{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import operator\n",
    "\n",
    "import math\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please, download the data to your working folder.On the webpage you can find its description. \n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Iris\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iris = pd.read_csv('iris.data',header=None, names=['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)', 'target names'])\n",
    "iris = pd.read_csv('iris.data',header=None, names=['sl', 'sw', 'pl', 'pw', 'target'])\n",
    "\n",
    "\n",
    "iris['target'] = iris['target'].map({'Iris-setosa':1, 'Iris-versicolor':0, 'Iris-virginica':0})\n",
    "\n",
    "X = iris.iloc[:, :-1]\n",
    "\n",
    "y = iris.iloc[:, -1]\n",
    "\n",
    "X = np.c_[np.ones((X.shape[0], 1)), X]\n",
    "\n",
    "# y = y[:, np.newaxis]\n",
    "\n",
    "theta = np.zeros((X.shape[1], 1))\n",
    "\n",
    "del iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42, shuffle=True)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.11, random_state=42, shuffle=True)\n",
    "del X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement the \"loss\" function for Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = lambda x: 1 / (1 + np.exp(-x))\n",
    "\n",
    "net_input = lambda theta, x: np.dot(x, theta)\n",
    "\n",
    "probability = lambda theta, x: sigmoid(net_input(theta, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(theta, x, y):\n",
    "    \"\"\" \n",
    "    Loss function implementation. \n",
    "  \n",
    "    This function uses some of above implemented functions. \n",
    "  \n",
    "    Parameters: \n",
    "    theta (array): Initial theta, which i choose all zeros\n",
    "    x (DataFrame): features\n",
    "    y (DataFrame): labels\n",
    "  \n",
    "    Returns: \n",
    "    float: total loss value \n",
    "  \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    m = x.shape[0]\n",
    "    \n",
    "    total_loss = -(1 / m) * np.sum(\n",
    "        y * np.log(probability(theta, x)) + (1 - y) * np.log(1 - probability(theta, x))\n",
    "    )\n",
    "    \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement the \"fit\" function gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.optimize import fmin_tnc\n",
    "# def fit(x, y, theta):\n",
    "#     opt_weights = fmin_tnc(func=loss_function, x0=theta,\n",
    "#                   fprime=gradient,args=(x, y.flatten()))\n",
    "#     return opt_weights[0]\n",
    "# parameters = fit(X_train, y_train, theta)\n",
    "# parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_gd(x, y, theta, lr = 0.01, n_iterations = 1000):\n",
    "    \"\"\" \n",
    "    Fit function implementation. \n",
    "  \n",
    "    This function minimize the loss value by gradient descent. \n",
    "  \n",
    "    Parameters: \n",
    "    theta (array): Initial theta, which i choose all zeros\n",
    "    x (DataFrame): features\n",
    "    y (DataFrame): labels\n",
    "    lr (float) : learning rate\n",
    "    n_iterations (int): number of iterations, steps of gradient descent\n",
    "  \n",
    "    Returns: \n",
    "    float: total loss value \n",
    "    array: fitted parameters\n",
    "  \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def gradient(theta, x, y):\n",
    "        m = x.shape[0]\n",
    "\n",
    "        return (1 / m) * np.dot(x.T, sigmoid(net_input(theta,   x)) - y)\n",
    "\n",
    "    \n",
    "    loss_ = []\n",
    "    y = y[:, np.newaxis]\n",
    "    \n",
    "    for _ in range(n_iterations):\n",
    "        theta -= lr * gradient(theta,x, y )\n",
    "        loss = loss_function(theta, x, y)\n",
    "        loss_.append(loss)\n",
    "        \n",
    "    return theta, loss_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement predict function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, theta, probab_threshold=0.5):\n",
    "    \"\"\" \n",
    "    Predict function implementation. \n",
    "  \n",
    "    This function does the prediction. \n",
    "  \n",
    "    Parameters: \n",
    "    theta (array): Initial theta, which i choose all zeros\n",
    "    x (DataFrame): features\n",
    "    probab_thresgold (float): from 0 to 1 float value for probability threshold\n",
    "  \n",
    "    Returns: \n",
    "    DataFrame: Predicted classes\n",
    "  \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    probab = probability(theta, x)\n",
    "    \n",
    "    predicted_classes = (probab >= probab_threshold).astype(int)\n",
    "    \n",
    "    return predicted_classes.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To evaluate the model, use accuracy, precision and recall metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predicted_classes, actual_classes):\n",
    "    \"\"\" \n",
    "    Accuracy function implementation. \n",
    "  \n",
    "    This function calculates the accuracy of prediction. \n",
    "  \n",
    "    Parameters: \n",
    "    predicted_classes (DataFrame): predicted classes\n",
    "    actual_classes (DataFrame): real labels of dataset\n",
    "  \n",
    "    Returns: \n",
    "    float: the percentage of accuracy\n",
    "  \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    accuracy = np.mean(predicted_classes == actual_classes)\n",
    "    \n",
    "    return accuracy * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(predicted_classes, actual_classes):\n",
    "    \"\"\" \n",
    "    Confusion matrix implementation. \n",
    "  \n",
    "    This function will be used in precision and recall calculation. \n",
    "  \n",
    "    Parameters: \n",
    "    predicted_classes (DataFrame): predicted classes\n",
    "    actual_classes (DataFrame): real labels of dataset\n",
    "  \n",
    "    Returns: \n",
    "    dictionary: confusion matrix\n",
    "  \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    TP = []\n",
    "    TN = []\n",
    "    FN = []\n",
    "    FP = []\n",
    "    \n",
    "#     actual_classes = actual_classes[:, np.newaxis].flatten()\n",
    "    actual_classes = actual_classes.values\n",
    "    \n",
    "    for i in range(len(actual_classes)):\n",
    "        TP.append(predicted_classes[i] & actual_classes[i])\n",
    "        TN.append(abs(predicted_classes[i]-1) & abs(actual_classes[i]-1))\n",
    "        FP.append(np.where(predicted_classes[i]-actual_classes[i] == 1, 1, 0))\n",
    "        FN.append(np.where(predicted_classes[i]-actual_classes[i] == -1, 1, 0))\n",
    "        \n",
    "    conf_mat = {\n",
    "        'TP': float(np.sum(TP)),\n",
    "        'TN': float(np.sum(TN)),\n",
    "        'FN': float(np.sum(FN)),\n",
    "        'FP': float(np.sum(FP))\n",
    "    }\n",
    "    \n",
    "    return conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(predicted_classes, actual_classes):\n",
    "    \"\"\" \n",
    "    Precision function implementation. \n",
    "  \n",
    "    This function calculates the precision of predictions by TP / TP + FP. \n",
    "  \n",
    "    Parameters: \n",
    "    predicted_classes (DataFrame): predicted classes\n",
    "    actual_classes (DataFrame): real labels of dataset\n",
    "  \n",
    "    Returns: \n",
    "    float: precision\n",
    "  \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    conf_mat = confusion_matrix(predicted_classes, actual_classes)\n",
    "    \n",
    "    prec = conf_mat['TP'] / np.where(conf_mat['TP'] + conf_mat['FP'] == 0.0, 1, conf_mat['TP'] + conf_mat['FP'])\n",
    "    \n",
    "    return prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(predicted_classes, actual_classes):\n",
    "    \"\"\" \n",
    "    Recall function implementation. \n",
    "  \n",
    "    This function calculates the recall of predictions by TP / TP + FN. \n",
    "  \n",
    "    Parameters: \n",
    "    predicted_classes (DataFrame): predicted classes\n",
    "    actual_classes (DataFrame): real labels of dataset\n",
    "  \n",
    "    Returns: \n",
    "    float: recall\n",
    "  \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    conf_mat = confusion_matrix(predicted_classes, actual_classes)\n",
    "    \n",
    "    rc = conf_mat['TP'] / np.where(conf_mat['TP'] + conf_mat['FN'] == 0.0, 1, conf_mat['TP'] + conf_mat['FN'] )\n",
    "    \n",
    "    return rc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the best learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, precision and recall for 1e-10 learning rate:  73.33333333333333%, 0.0, 0.0\n",
      "accuracy, precision and recall for 1e-09 learning rate:  73.33333333333333%, 0.0, 0.0\n",
      "accuracy, precision and recall for 1e-08 learning rate:  73.33333333333333%, 0.0, 0.0\n",
      "accuracy, precision and recall for 1e-07 learning rate:  73.33333333333333%, 0.0, 0.0\n",
      "accuracy, precision and recall for 1e-06 learning rate:  73.33333333333333%, 0.0, 0.0\n",
      "accuracy, precision and recall for 1e-05 learning rate:  73.33333333333333%, 0.0, 0.0\n",
      "accuracy, precision and recall for 0.0001 learning rate:  73.33333333333333%, 0.0, 0.0\n",
      "accuracy, precision and recall for 0.001 learning rate:  100.0%, 1.0, 1.0\n",
      "accuracy, precision and recall for 0.01 learning rate:  100.0%, 1.0, 1.0\n",
      "accuracy, precision and recall for 0.1 learning rate:  100.0%, 1.0, 1.0\n",
      "accuracy, precision and recall for 1 learning rate:  100.0%, 1.0, 1.0\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [1e-10, 1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1]\n",
    "\n",
    "# theta = np.zeros((X_train.shape[1], 1))\n",
    "\n",
    "for lr in learning_rates:\n",
    "    theta = np.zeros((X_train.shape[1], 1))\n",
    "    \n",
    "    fitted_parameters = fit_gd(X_train, y_train, theta, n_iterations=1000, lr=lr)[0]\n",
    "\n",
    "    predicted_classes = predict(X_validation, fitted_parameters)\n",
    "    \n",
    "    print('accuracy, precision and recall for {} learning rate:  {}%, {}, {}'.format(lr, accuracy(predicted_classes, y_validation), precision(predicted_classes, y_validation), recall(predicted_classes, y_validation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.zeros((X_train.shape[1], 1))\n",
    "final_params, loss_output = fit_gd(X_train, y_train, theta, n_iterations=1000, lr=0.001 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot loss output depending on iteration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, len(loss_output) + 1), loss_output, label = 'loss value')\n",
    "\n",
    "plt.xlabel('Iterations')\n",
    "\n",
    "plt.ylabel('loss')\n",
    "\n",
    "plt.title('Logistic Regression')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report the prediction accuracy on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = predict(X_test, final_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(predicted_classes, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision(predicted_classes, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall(predicted_classes, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-NN classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training/validation/test datasets with 80/10/10 ratio. Make sure that they do not overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv('iris.data',header=None, names=['sl', 'sw', 'pl', 'pw', 'target'])\n",
    "iris['target'] = pd.factorize(iris.target)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(iris.iloc[:, :4], iris.iloc[:, 4:], test_size=0.10, random_state=42, shuffle=True)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.11, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They don't overlap\n"
     ]
    }
   ],
   "source": [
    "if (X_train.shape[0] + X_test.shape[0] + X_validation.shape[0] == iris.iloc[:, :4].shape[0]):\n",
    "    print('They don\\'t overlap')\n",
    "else:\n",
    "    print('They overlap')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement the K-NN algorithm: create two functions, fit() - that is responsible for training and predict() - which is responsible for predicting the values for new data points\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_knn(X_train, X_to_predict, k = 3):\n",
    "    \"\"\" \n",
    "    Fit function implementation. \n",
    "  \n",
    "    This is the fit function of KNN algorithm which uses euclidean distance as distance metric \n",
    "  \n",
    "    Parameters: \n",
    "    X_train (DataFrame): train dataset\n",
    "    X_to_predict (DataFrame): the dataset for which we want to do prediction\n",
    "  \n",
    "    Returns: \n",
    "    dictionary: k neighbours for each object of X_to_pedict dataset\n",
    "  \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def euclidean_distance(sample1, sample2, length):\n",
    "        distance = 0\n",
    "\n",
    "        for x in range(length):\n",
    "            distance += (sample1[x] - sample2[x]) ** 2\n",
    "\n",
    "        return math.sqrt(distance)\n",
    "    \n",
    "    def get_index_of_neighbours(training_set, test_instance, k):\n",
    "        distances = []\n",
    "\n",
    "        length = len(test_instance) - 1\n",
    "\n",
    "        for idx in range(len(training_set)):\n",
    "            dist = euclidean_distance(test_instance,training_set[idx : idx + 1].values[0], length)\n",
    "\n",
    "            distances.append((training_set[idx : idx + 1].index.values.astype(int)[0], dist))\n",
    "\n",
    "        distances.sort(key = operator.itemgetter(1))\n",
    "\n",
    "        neighbors = []\n",
    "\n",
    "        for x in range(k):\n",
    "            neighbors.append(distances[x][0])\n",
    "\n",
    "        return neighbors\n",
    "\n",
    "\n",
    "    neighbours = {}\n",
    "    \n",
    "    for test_instance_index in range(len(X_to_predict)):\n",
    "        test_instance = X_to_predict[test_instance_index : test_instance_index + 1]\n",
    "        \n",
    "        neighbours[test_instance.index.values.astype(int)[0]] = (get_index_of_neighbours(X_train, test_instance.values[0], k))\n",
    "        \n",
    "    return neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_knn(fitted_neighbours):\n",
    "    \"\"\" \n",
    "    Prediction function implementation. \n",
    "  \n",
    "    This function does prediction of X_to_Predict dataset's objects \n",
    "  \n",
    "    Parameters: \n",
    "    fitted_neighbours: This is the result of fit_knn function which is a dictionary consisting of index as a key and neighbours as a value\n",
    "  \n",
    "    Returns: \n",
    "    DataFrame: predicted classes of each element\n",
    "  \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def prediction_specific_row(index_of_neighbours):\n",
    "        neighbours_classes = []\n",
    "\n",
    "        for row_index in index_of_neighbours:\n",
    "            neighbours_classes.append(y_train.loc[row_index, :][0])\n",
    "\n",
    "        return neighbours_classes\n",
    "    def find_class(neighbors):\n",
    "        votes = {}\n",
    "\n",
    "        for clas in range(len(neighbors)):\n",
    "            if neighbors[clas] in votes:\n",
    "                votes[neighbors[clas]] += 1\n",
    "            else:\n",
    "                votes[neighbors[clas]] = 1\n",
    "\n",
    "        sorted_votes = sorted(votes.items(), key = operator.itemgetter(1), reverse = True)\n",
    "\n",
    "        return sorted_votes[0][0]\n",
    "    \n",
    "    \n",
    "    neighbours_classes = {}\n",
    "    \n",
    "    for index_of_row_prediction, neighbours in fitted_neighbours.items():\n",
    "        neighbours_classes[index_of_row_prediction] = prediction_specific_row(neighbours)\n",
    "    \n",
    "    index = []\n",
    "    predicted_classes = []\n",
    "    \n",
    "    for index_of_row_prediction, classes_of_neighbours in neighbours_classes.items():\n",
    "        index.append(index_of_row_prediction)\n",
    "        predicted_classes.append(find_class(classes_of_neighbours))\n",
    "        \n",
    "    prediction_df = pd.DataFrame(predicted_classes, index=index, columns=['prediction'])\n",
    "    \n",
    "    return prediction_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For evaluation we will use \"accuracy\" metric - implement it :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(actual, predicted):\n",
    "    \"\"\" \n",
    "    Accuracy function implementation. \n",
    "  \n",
    "    This function calculates the accuracy of prediction \n",
    "  \n",
    "    Parameters: \n",
    "    actual (DataFrame): labels\n",
    "    predicted (DataFrame): this is the result of prediction function\n",
    "  \n",
    "    Returns: \n",
    "    float: this is the percentage of prediction accuracy\n",
    "  \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    correct = 0\n",
    "    \n",
    "    for row_number in range (len(actual)):\n",
    "        if actual.values[row_number][0] == predicted.values[row_number][0]:\n",
    "            correct += 1\n",
    "            \n",
    "    return (correct/float(len(actual))) * 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the best \"k\" value and report the accuracy for all k-values you have tried on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for k = 1 is equal to 100.0 %\n",
      "accuracy for k = 2 is equal to 100.0 %\n",
      "accuracy for k = 3 is equal to 93.3 %\n",
      "accuracy for k = 4 is equal to 93.3 %\n",
      "accuracy for k = 5 is equal to 93.3 %\n",
      "accuracy for k = 6 is equal to 100.0 %\n",
      "accuracy for k = 7 is equal to 100.0 %\n",
      "accuracy for k = 8 is equal to 100.0 %\n",
      "accuracy for k = 9 is equal to 100.0 %\n",
      "accuracy for k = 10 is equal to 100.0 %\n"
     ]
    }
   ],
   "source": [
    "K = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "for k in K:\n",
    "    model = fit_knn(X_train, X_validation, k)\n",
    "    \n",
    "    predict_validation = prediction_knn(model)\n",
    "    \n",
    "    accuracy_validation = accuracy(y_validation, predict_validation)\n",
    "    \n",
    "    print('accuracy for k = {} is equal to {} %'.format(k, round(accuracy_validation, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering that a small value of k means that noise will have a greater impact on the result, and a large value will make it computationally expensive, I will choose k = 6 as the best value for k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report the accuracy for the best value of k on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on the test data is equal to 80.0 %\n"
     ]
    }
   ],
   "source": [
    "model = fit_knn(X_train, X_test, 6)\n",
    "    \n",
    "predict_test = prediction_knn(model)\n",
    "    \n",
    "accuracy_test = accuracy(y_test, predict_test)\n",
    "    \n",
    "print('accuracy on the test data is equal to {} %'.format(round(accuracy_test, 3)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
